{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crisis-data-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gt = pd.read_csv('data/data-gold.csv')\n",
    "df_gt = df_gt[df_gt['_golden'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selectivity of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not informative: personal only                                                        0.374356\n",
      "Can not judge (not in English, too short, etc.)                                       0.126674\n",
      "Informative: damage (building, road, lines, etc.)                                     0.109681\n",
      "Informative: caution or advice                                                        0.064882\n",
      "Informative: other type of photos/videos (not in the above classes)                   0.063852\n",
      "Informative: information source with extensive coverage (radio, tv, website, etc.)    0.063337\n",
      "Informative: other                                                                    0.059732\n",
      "Not informative: unrelated to the disaster                                            0.043769\n",
      "Informative: offers/gives donations of money, goods, or free services                 0.027291\n",
      "Informative: requests donations of money, goods, or free services                     0.024717\n",
      "Informative: celebrities or authorities react to the event or visit the area          0.022142\n",
      "Informative: casualties (people injured or dead)                                      0.018538\n",
      "Informative: people missing, or lost people found                                     0.001030\n",
      "Name: type_of_message, dtype: float64\n",
      "------------------------------------\n",
      "the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event:      0.1791967044284243\n"
     ]
    }
   ],
   "source": [
    "print(df_gt['type_of_message'].value_counts()/len(df_gt))\n",
    "print('------------------------------------')\n",
    "print('the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event:      {}'.format(len(df_gt[(df_gt['the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event'] == True)]) / len(df_gt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### % of IN tweets for (3 predicates):\n",
    "author_is_eye_witness_of_the_event ^ Informative ^ damage (building, road, lines, etc.) = 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03038105046343975"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relevant = df_gt[(df_gt['the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event'] == True) & (\n",
    "    df_gt['type_of_message'] == 'Informative: damage (building, road, lines, etc.)')]\n",
    "\n",
    "len(df_relevant) / len(df_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### % of IN tweets for (3 predicates):\n",
    "not author_is_eye_witness_of_the_event ^ Informative ^ damage (building, road, lines, etc.) = 8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07929969104016478"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relevant = df_gt[(df_gt['the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event'] != True) & (\n",
    "    df_gt['type_of_message'] == 'Informative: damage (building, road, lines, etc.)')]\n",
    "\n",
    "len(df_relevant) / len(df_gt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make 3 predicates - Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data-crowdsourced.csv')\n",
    "df = df[df['_golden'] == False]\n",
    "# df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### author_is_eye_witness_of_the_event ^ Informative ^ damage (building, road, lines, etc.) = 3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eye_witness\n",
    "# the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event\n",
    "data = []\n",
    "item_id = 0\n",
    "## Compute workers' accuracy\n",
    "informative_true_votes = 0\n",
    "eye_witness_true_votes = 0\n",
    "damage_true_votes = 0\n",
    "y_true_votes = 0\n",
    "for unit_id in df_gt['_unit_id'].unique():\n",
    "    item_df = df[df['_unit_id'] == unit_id]\n",
    "    eye_witness_in = eye_witness_out = 0\n",
    "    informative_in = informative_out = 0\n",
    "    damage_in = damage_out = 0\n",
    "    y_in = y_out = 0\n",
    "    \n",
    "    gt_witness = df_gt[df_gt['_unit_id']==unit_id]['the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event'].values[0] == True\n",
    "    gt_inf = 'Informative' in df_gt[df_gt['_unit_id']==unit_id]['type_of_message'].values[0]\n",
    "    gt_damage = 'damage' in df_gt[df_gt['_unit_id']==unit_id]['type_of_message'].values[0]\n",
    "    y = 1 if gt_witness and gt_inf and gt_damage else 0\n",
    "    for row_id, row in item_df.iterrows():\n",
    "        if row['the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event'] == True:\n",
    "            eye_witness_in += 1\n",
    "        else:\n",
    "            eye_witness_out += 1\n",
    "        if 'Informative' in row['type_of_message']:\n",
    "            informative_in += 1\n",
    "        else:\n",
    "            informative_out += 1\n",
    "        if 'damage' in row['type_of_message']:\n",
    "            damage_in += 1\n",
    "        else:\n",
    "            damage_out += 1\n",
    "            \n",
    "        ## Compute workers' accuracy\n",
    "        if (row['the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event'] == True) == gt_witness:\n",
    "            eye_witness_true_votes += 1\n",
    "        if ('Informative' in row['type_of_message']) == gt_inf:\n",
    "            informative_true_votes += 1\n",
    "        if ('damage' in row['type_of_message']) == gt_damage:\n",
    "            damage_true_votes += 1\n",
    "        y_crowdsourced = (row['the_author_of_the_tweet_seems_to_be_an_eye_witness_of_the_event'] == True) and ('Informative' in row['type_of_message']) and ('damage' in row['type_of_message'])\n",
    "        if y_crowdsourced == y:\n",
    "            y_true_votes += 1\n",
    "            \n",
    "        if y_crowdsourced:\n",
    "            y_in += 1\n",
    "        else:\n",
    "            y_out +=1\n",
    "    text = df_gt[df_gt['_unit_id'] == unit_id]['tweet'].values[0]\n",
    "    data.append([item_id, int(gt_witness), eye_witness_in, eye_witness_out, int(gt_inf), informative_in, informative_out, int(gt_damage), damage_in, damage_out,\n",
    "                y_in, y_out, y, text])\n",
    "    item_id += 1\n",
    "df_tr = pd.DataFrame(data, columns=['item_id', 'eye_witness', 'eye_witness_in', 'eye_witness_out', 'informative', 'informative_in', 'informative_out',\n",
    "                'damage', 'damage_in', 'damage_out', 'Y_in', 'Y_out', 'Y', 'text'])\n",
    "\n",
    "# df_tr.to_csv('data/crisis_transformed_witness_inf_damage.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crowd Accuracy on 'informative' pred: 0.855\n",
      "Crowd Accuracy on 'eye witness' pred: 0.8741666666666666\n",
      "Crowd Accuracy on 'damage' pred: 0.9035\n",
      "----------------------------\n",
      "Crowd Accuracy on 'informative^witness^damage': 0.9691666666666666\n"
     ]
    }
   ],
   "source": [
    "print(\"Crowd Accuracy on 'informative' pred: {}\".format(informative_true_votes / len(df)))\n",
    "print(\"Crowd Accuracy on 'eye witness' pred: {}\".format(eye_witness_true_votes / len(df)))\n",
    "print(\"Crowd Accuracy on 'damage' pred: {}\".format(damage_true_votes / len(df)))\n",
    "print('----------------------------')\n",
    "print(\"Crowd Accuracy on 'informative^witness^damage': {}\".format(y_true_votes / len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming, Lemmatising and cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:486: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "text_cleaned = []\n",
    "\n",
    "df = pd.read_csv('data/crisis_transformed_witness_inf_damage.csv')\n",
    "\n",
    "# Replace all numbers with special strings\n",
    "regx = re.compile(r\"\\b[\\d.]+\\b\")\n",
    "porter = PorterStemmer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    text = row['text']\n",
    "#     with stemming\n",
    "#     text = [porter.stem(word.strip()) for word in nltk.word_tokenize(text.lower()) if (word not in string.punctuation) and (word not in stopwords.words(\"english\"))]\n",
    "    \n",
    "#     # without stemming\n",
    "#     text = [word.strip() for word in nltk.word_tokenize(text.lower()) if (word not in string.punctuation) and (word not in stopwords.words(\"english\"))]\n",
    "    \n",
    "#     # with lemmatizer\n",
    "    text = [wordnet_lemmatizer.lemmatize(word.strip()) for word in nltk.word_tokenize(text.lower()) if (word not in string.punctuation) and (word not in stopwords.words(\"english\"))]\n",
    "         \n",
    "    text_cleaned.append(text)\n",
    "    \n",
    "# Findining Phrases (ie bi-grams)\n",
    "# train bi-grams\n",
    "bigram = Phrases()\n",
    "bigram.add_vocab(text_cleaned)\n",
    "\n",
    "# create phrases\n",
    "text_cleaned_phrases = []\n",
    "for text_ in text_cleaned:\n",
    "    text_cleaned_phrases.append(bigram[text_])\n",
    "\n",
    "text_cleaned_phrases_joined = [' '.join(text) for text in text_cleaned_phrases]\n",
    "df['text'] = pd.Series(text_cleaned_phrases_joined, index=df.index)\n",
    "df['text'] = df['text'].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem)) \n",
    "df.rename(columns={'text':'tokens'}, inplace=True)\n",
    "\n",
    "# df.to_csv('data/crisis-lemmatized_witness_inf_damage.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
